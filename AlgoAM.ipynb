{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSum(self, nums: List[int], target: int) -> List[int]:\n",
    "    su = {}\n",
    "    for i, num in enumerate(nums):\n",
    "        x = target - num\n",
    "        if x in su:\n",
    "            return sorted([i, su[x]])            \n",
    "        su[num] = i\n",
    "\n",
    "    return [-1,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Palindromic Substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution(object):\n",
    "    def longestPalindrome(self, s):\n",
    "        \"\"\"\n",
    "        :type s: str\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        n = len(s)\n",
    "        maxlen = 0\n",
    "        ans = ''\n",
    "        \n",
    "        for i in range(n):            \n",
    "            # odd\n",
    "            start, end = i, i\n",
    "            while start >= 0 and end < n and s[start] == s[end]:\n",
    "                    start -= 1\n",
    "                    end += 1 \n",
    "            if end - start - 1 > maxlen:\n",
    "                \n",
    "                ans = s[start+1:end]\n",
    "                maxlen = end - start - 1 \n",
    "                \n",
    "            # even\n",
    "            start, end = i, i+1\n",
    "            while start >= 0 and end < n and s[start] == s[end]:\n",
    "                    start -= 1\n",
    "                    end += 1 \n",
    "            if end - start - 1 > maxlen:\n",
    "                ans = s[start+1:end]\n",
    "                maxlen = end - start - 1 \n",
    "                \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Labels\n",
    "\n",
    "A string S of lowercase letters is given. We want to partition this string into as many parts as possible so that each letter appears in at most one part, and return a list of integers representing the size of these parts.\n",
    "\n",
    "\n",
    "Input: S = \"ababcbacadefegdehijhklij\"\n",
    "\n",
    "Output: [9,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionLabels(self, S: str) -> List[int]:\n",
    "    rightmost = {c:i for i, c in enumerate(S)}\n",
    "    left = right = 0 \n",
    "    res = [] \n",
    "    for i, c in enumerate(S):\n",
    "        right = max(right, rightmost[c])\n",
    "        if i == right:\n",
    "            res.append(right-left+1)\n",
    "            left = i + 1 \n",
    "    return res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorder Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorderLogFiles(self, logs: List[str]) -> List[str]:\n",
    "    digits = []\n",
    "    letters = []\n",
    "\n",
    "    for log in logs:\n",
    "        if log.split()[1].isdigit():\n",
    "            digits.append(log)\n",
    "        else:\n",
    "            letters.append(log)\n",
    "    print(letters)\n",
    "    letters.sort(key = lambda x: x.split()[1])\n",
    "    letters.sort(key = lambda x: x.split()[1:])\n",
    "    res = letters + digits\n",
    "    return res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trapping Water\n",
    "\n",
    "![](https://assets.leetcode.com/uploads/2018/10/22/rainwatertrap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trap(self, heights: List[int]) -> int:\n",
    "    if not heights:\n",
    "        return 0\n",
    "    rain = maxleft = maxright = 0\n",
    "    left, right = 0, len(heights) - 1 \n",
    "    while left < right:\n",
    "        if heights[left] < heights[right]:\n",
    "            maxleft = max(heights[left], maxleft)\n",
    "            rain += maxleft - heights[left]\n",
    "            left += 1\n",
    "        else:\n",
    "            maxright = max(heights[right], maxright)\n",
    "            rain += maxright - heights[right]\n",
    "            right -= 1\n",
    "    return rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Two Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTwoNumbers(self, l1, l2):\n",
    "        \"\"\"\n",
    "        :type l1: ListNode\n",
    "        :type l2: ListNode\n",
    "        :rtype: ListNode\n",
    "        \"\"\"\n",
    "        l3 = head = ListNode(-1)\n",
    "        res = 0\n",
    "        while l1 and l2:\n",
    "            val = l1.val + l2.val + res\n",
    "            res = 0\n",
    "            if val >= 10:\n",
    "                res = 1\n",
    "                val -= 10\n",
    "            l3.next = ListNode(val)\n",
    "            l1 = l1.next\n",
    "            l2 = l2.next\n",
    "            l3 = l3.next\n",
    "\n",
    "        while l1:\n",
    "            val = l1.val + res\n",
    "            res = 0\n",
    "            if val >= 10:\n",
    "                res = 1\n",
    "                val -= 10\n",
    "            l3.next = ListNode(val)\n",
    "            l1 = l1.next\n",
    "            l3 = l3.next\n",
    "        \n",
    "        while l2:\n",
    "            val = l2.val + res\n",
    "            res = 0\n",
    "            if val >= 10:\n",
    "                res = 1\n",
    "                val -= 10\n",
    "            l3.next = ListNode(val)\n",
    "            l2 = l2.next\n",
    "            l3 = l3.next\n",
    "\n",
    "        \n",
    "        if res:\n",
    "            l3.next = ListNode(res)\n",
    "            res = 0 \n",
    "            l3 = l3.next\n",
    "        \n",
    "        return head.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Random List\n",
    "A linked list is given such that each node contains an additional random pointer which could point to any node in the list or null.\n",
    "\n",
    "Return a deep copy of the list.\n",
    "![](https://discuss.leetcode.com/uploads/files/1470150906153-2yxeznm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O(2n)\n",
    "def copyRandomList(self, head):\n",
    "    dic = dict()\n",
    "    m = n = head\n",
    "    while m:\n",
    "        dic[m] = RandomListNode(m.label)\n",
    "        m = m.next\n",
    "    while n:\n",
    "        dic[n].next = dic.get(n.next)\n",
    "        dic[n].random = dic.get(n.random)\n",
    "        n = n.next\n",
    "    return dic.get(head)\n",
    "\n",
    "#O(n)\n",
    "def copyRandomList(self, head):\n",
    "    dic = collections.defaultdict(lambda: RandomListNode(0))\n",
    "    dic[None] = None\n",
    "    n = head\n",
    "    while n:\n",
    "        dic[n].label = n.label\n",
    "        dic[n].next = dic[n.next]\n",
    "        dic[n].random = dic[n.random]\n",
    "        n = n.next\n",
    "    return dic[head]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Tree Zigzag Level Order Traversal\n",
    "\n",
    "\n",
    "```\n",
    "For example:\n",
    "Given binary tree [3,9,20,null,null,15,7],\n",
    "    3\n",
    "   / \\\n",
    "  9  20\n",
    "    /  \\\n",
    "   15   7\n",
    "return its zigzag level order traversal as:\n",
    "[\n",
    "  [3],\n",
    "  [20,9],\n",
    "  [15,7]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for a binary tree node.\n",
    "# class TreeNode:\n",
    "#     def __init__(self, x):\n",
    "#         self.val = x\n",
    "#         self.left = None\n",
    "#         self.right = None\n",
    "from collections import deque\n",
    "class Solution:\n",
    "    def zigzagLevelOrder(self, root: TreeNode) -> List[List[int]]:\n",
    "        if not root:\n",
    "            return []\n",
    "        deck = deque()\n",
    "        deck.append(root)\n",
    "        res = [] \n",
    "        reverse = 0\n",
    "        while deck:\n",
    "            size = len(deck)\n",
    "            tmp = []\n",
    "            for i in range(size):\n",
    "                node = deck.popleft()\n",
    "                tmp.append(node.val)\n",
    "                if node.left:\n",
    "                    deck.append(node.left)\n",
    "                if node.right:\n",
    "                    deck.append(node.right)\n",
    "            res.append(tmp[::-1]) if reverse else res.append(tmp)\n",
    "            reverse = 1 - reverse\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph(BFS and DFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Solution:\n",
    "    def numIslands(self, grid: List[List[str]]) -> int:\n",
    "        if not grid:\n",
    "            return 0\n",
    "        self.count = 0 \n",
    "        dirs = [(1,0),(0,1),(-1,0),(0,-1)]\n",
    "        m, n = len(grid), len(grid[0])\n",
    "        def bfs(x, y):\n",
    "            self.count += 1 \n",
    "            grid[x][y] = '-1' # visited\n",
    "            deck = deque()\n",
    "            deck.append((x,y))\n",
    "            while deck:\n",
    "                x, y = deck.popleft()\n",
    "                for dx, dy in dirs:\n",
    "                    xd, yd = x + dx, y + dy\n",
    "                    if 0 <= xd < m and 0 <= yd < n and grid[xd][yd] == '1':\n",
    "                        grid[xd][yd] = '-1' #visited\n",
    "                        deck.append((xd, yd))\n",
    "        \n",
    "        for x in range(m):\n",
    "            for y in range(n):\n",
    "                if grid[x][y] == '1':\n",
    "                    bfs(x,y)\n",
    "    \n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snakes and Ladders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Ladder \n",
    "```\n",
    "Input:\n",
    "beginWord = \"hit\",\n",
    "endWord = \"cog\",\n",
    "wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "\n",
    "Output: 5\n",
    "\n",
    "Explanation: As one shortest transformation is \"hit\" -> \"hot\" -> \"dot\" -> \"dog\" -> \"cog\",\n",
    "return its length 5.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Solution:\n",
    "    def ladderLength(self, begin: str, end: str, wordList: List[str]) -> int:   \n",
    "        wordSet = set(wordList)\n",
    "        if end not in wordSet:\n",
    "            return 0\n",
    "        \n",
    "        n = len(begin)\n",
    "        \n",
    "        chlist = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        deck = deque()\n",
    "        deck.append((begin, 1))\n",
    "        \n",
    "        while deck:\n",
    "            cur_word, cur_len = deck.popleft()\n",
    "            for ch in chlist:\n",
    "                for j in range(n):\n",
    "                    new_word = cur_word[:j] + ch + cur_word[j+1:]\n",
    "                    if new_word in wordSet:\n",
    "                        if new_word == end:\n",
    "                            return cur_len + 1\n",
    "                        deck.append((new_word, cur_len+1))\n",
    "                        wordSet.remove(new_word)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash (Set & Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Commom words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostCommonWord(self, paragraph, banned):\n",
    "    for c in \"!?',;.\": paragraph = paragraph.replace(c, \" \")\n",
    "    d, res, count = {},\"\",0\n",
    "    for word in paragraph.lower().split():\n",
    "        if word in banned:\n",
    "            continue;\n",
    "        elif word in d:\n",
    "            d[word] += 1\n",
    "        else:\n",
    "            d[word] = 1\n",
    "        if d[word] > count:\n",
    "            count = d[word]\n",
    "            res = word\n",
    "    return res\n",
    "\n",
    "import re, collections\n",
    "def mostCommonWord(self, paragraph, banned):\n",
    "    tokens = [token for token in re.findall(r\"([a-zA-Z]+)\",  paragraph.lower()) if token not in banned]\n",
    "    mostComm = collections.Counter(tokens).most_common(1)\n",
    "    return mostComm[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prison Cells After N Days\n",
    "\n",
    "There are 8 prison cells in a row, and each cell is either occupied or vacant.\n",
    "\n",
    "Each day, whether the cell is occupied or vacant changes according to the following rules:\n",
    "\n",
    "If a cell has two adjacent neighbors that are both occupied or both vacant, then the cell becomes occupied.\n",
    "Otherwise, it becomes vacant.\n",
    "(Note that because the prison is a row, the first and the last cells in the row can't have two adjacent neighbors.)\n",
    "\n",
    "We describe the current state of the prison in the following way: cells[i] == 1 if the i-th cell is occupied, else cells[i] == 0.\n",
    "\n",
    "Given the initial state of the prison, return the state of the prison after N days (and N such changes described above.)\n",
    "\n",
    "```\n",
    "Example 1:\n",
    "\n",
    "Input: cells = [0,1,0,1,1,0,0,1], N = 7\n",
    "Output: [0,0,1,1,0,0,0,0]\n",
    "Explanation: \n",
    "The following table summarizes the state of the prison on each day:\n",
    "Day 0: [0, 1, 0, 1, 1, 0, 0, 1]\n",
    "Day 1: [0, 1, 1, 0, 0, 0, 0, 0]\n",
    "Day 2: [0, 0, 0, 0, 1, 1, 1, 0]\n",
    "Day 3: [0, 1, 1, 0, 0, 1, 0, 0]\n",
    "Day 4: [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "Day 5: [0, 1, 1, 1, 0, 1, 0, 0]\n",
    "Day 6: [0, 0, 1, 0, 1, 1, 0, 0]\n",
    "Day 7: [0, 0, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "Example 2:\n",
    "\n",
    "Input: cells = [1,0,0,1,0,0,1,0], N = 1000000000\n",
    "Output: [0,0,1,1,1,1,1,0]\n",
    " \n",
    "\n",
    "Note:\n",
    "\n",
    "cells.length == 8\n",
    "cells[i] is in {0, 1}\n",
    "1 <= N <= 10^9\n",
    "\n",
    "```\n",
    "So, the state of the cells repeat every after 14 days. If N>14 , we can simply do N = N%14. The only problem is when N%14 == 0, then we do not want the 0th state, but the 14th state, that is the last state.\n",
    "So, I just hardcoded it. Rest all is exactly the same.\n",
    "Please find the solution below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prisonAfterNDays(self, cells, N):\n",
    "    seen = {str(cells): N}\n",
    "    while N:\n",
    "        seen.setdefault(str(cells), N)\n",
    "        N -= 1\n",
    "        cells = [0] + [cells[i - 1] ^ cells[i + 1] ^ 1 for i in range(1, 7)] + [0]\n",
    "        if str(cells) in seen:\n",
    "            N %= seen[str(cells)] - N\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRU Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class LRUCache:\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()\n",
    "\n",
    "    def get(self, key: int) -> int:\n",
    "        if key not in self.cache:\n",
    "            return -1\n",
    "        value = self.cache.pop(key)\n",
    "        self.cache[key] = value\n",
    "        return value\n",
    "\n",
    "    def put(self, key: int, value: int) -> None:\n",
    "        if key in self.cache:\n",
    "            self.cache.pop(key)\n",
    "        elif len(self.cache) == self.capacity:\n",
    "            self.cache.popitem(last=False)\n",
    "        self.cache[key] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFU Cache\n",
    "\n",
    "![](https://assets.leetcode.com/users/k_kkkyle/image_1545365613.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, key, val):\n",
    "        self.key = key\n",
    "        self.val = val\n",
    "        self.freq = 1\n",
    "        self.prev = self.next = None\n",
    "\n",
    "class DLinkedList:\n",
    "    \"\"\" An implementation of doubly linked list.\n",
    "\n",
    "    Two APIs provided:\n",
    "    \n",
    "    append(node): append the node to the head of the linked list.\n",
    "    pop(node=None): remove the referenced node. \n",
    "                    If None is given, remove the one from tail, which is the least recently used.\n",
    "                    \n",
    "    Both operation, apparently, are in O(1) complexity.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._sentinel = Node(None, None) # dummy node\n",
    "        self._sentinel.next = self._sentinel.prev = self._sentinel\n",
    "        self._size = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._size\n",
    "    \n",
    "    def append(self, node):\n",
    "        node.next = self._sentinel.next\n",
    "        node.prev = self._sentinel\n",
    "        node.next.prev = node\n",
    "        self._sentinel.next = node\n",
    "        self._size += 1\n",
    "    \n",
    "    def pop(self, node=None):\n",
    "        if self._size == 0:\n",
    "            return\n",
    "        \n",
    "        if not node:\n",
    "            node = self._sentinel.prev\n",
    "\n",
    "        node.prev.next = node.next\n",
    "        node.next.prev = node.prev\n",
    "        self._size -= 1\n",
    "        \n",
    "        return node\n",
    "        \n",
    "class LFUCache:\n",
    "    def __init__(self, capacity):\n",
    "        \"\"\"\n",
    "        :type capacity: int\n",
    "        \n",
    "        Three things to maintain:\n",
    "        \n",
    "        1. a dict, named as `self._node`, for the reference of all nodes given key.\n",
    "           That is, O(1) time to retrieve node given a key.\n",
    "           \n",
    "        2. Each frequency has a doubly linked list, store in `self._freq`, where key\n",
    "           is the frequency, and value is an object of `DLinkedList`\n",
    "        \n",
    "        3. The min frequency through all nodes. We can maintain this in O(1) time, taking\n",
    "           advantage of the fact that the frequency can only increment by 1. Use the following\n",
    "           two rules:\n",
    "           \n",
    "           Rule 1: Whenever we see the size of the DLinkedList of current min frequency is 0,\n",
    "                   the min frequency must increment by 1.\n",
    "           \n",
    "           Rule 2: Whenever put in a new (key, value), the min frequency must 1 (the new node)\n",
    "           \n",
    "        \"\"\"\n",
    "        self._size = 0\n",
    "        self._capacity = capacity\n",
    "        \n",
    "        self._node = dict() # key: Node\n",
    "        self._freq = collections.defaultdict(DLinkedList)\n",
    "        self._minfreq = 0\n",
    "        \n",
    "        \n",
    "    def _update(self, node):\n",
    "        \"\"\" \n",
    "        This is a helper function that used in the following two cases:\n",
    "        \n",
    "            1. when `get(key)` is called; and\n",
    "            2. when `put(key, value)` is called and the key exists.\n",
    "         \n",
    "        The common point of these two cases is that:\n",
    "        \n",
    "            1. no new node comes in, and\n",
    "            2. the node is visited one more times -> node.freq changed -> \n",
    "               thus the place of this node will change\n",
    "        \n",
    "        The logic of this function is:\n",
    "        \n",
    "            1. pop the node from the old DLinkedList (with freq `f`)\n",
    "            2. append the node to new DLinkedList (with freq `f+1`)\n",
    "            3. if old DlinkedList has size 0 and self._minfreq is `f`,\n",
    "               update self._minfreq to `f+1`\n",
    "        \n",
    "        All of the above opeartions took O(1) time.\n",
    "        \"\"\"\n",
    "        freq = node.freq\n",
    "        \n",
    "        self._freq[freq].pop(node)\n",
    "        if self._minfreq == freq and not self._freq[freq]:\n",
    "            self._minfreq += 1\n",
    "        \n",
    "        node.freq += 1\n",
    "        freq = node.freq\n",
    "        self._freq[freq].append(node)\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"\n",
    "        Through checking self._node[key], we can get the node in O(1) time.\n",
    "        Just performs self._update, then we can return the value of node.\n",
    "        \n",
    "        :type key: int\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        if key not in self._node:\n",
    "            return -1\n",
    "        \n",
    "        node = self._node[key]\n",
    "        self._update(node)\n",
    "        return node.val\n",
    "\n",
    "    def put(self, key, value):\n",
    "        \"\"\"\n",
    "        If `key` already exists in self._node, we do the same operations as `get`, except\n",
    "        updating the node.val to new value.\n",
    "        \n",
    "        Otherwise, the following logic will be performed\n",
    "        \n",
    "        1. if the cache reaches its capacity, pop the least frequently used item. (*)\n",
    "        2. add new node to self._node\n",
    "        3. add new node to the DLinkedList with frequency 1\n",
    "        4. reset self._minfreq to 1\n",
    "        \n",
    "        (*) How to pop the least frequently used item? Two facts:\n",
    "        \n",
    "        1. we maintain the self._minfreq, the minimum possible frequency in cache.\n",
    "        2. All cache with the same frequency are stored as a DLinkedList, with\n",
    "           recently used order (Always append at head)\n",
    "          \n",
    "        Consequence? ==> The tail of the DLinkedList with self._minfreq is the least\n",
    "                         recently used one, pop it...\n",
    "        \n",
    "        :type key: int\n",
    "        :type value: int\n",
    "        :rtype: void\n",
    "        \"\"\"\n",
    "        if self._capacity == 0:\n",
    "            return\n",
    "        \n",
    "        if key in self._node:\n",
    "            node = self._node[key]\n",
    "            self._update(node)\n",
    "            node.val = value\n",
    "        else:\n",
    "            if self._size == self._capacity:\n",
    "                node = self._freq[self._minfreq].pop()\n",
    "                del self._node[node.key]\n",
    "                self._size -= 1\n",
    "                \n",
    "            node = Node(key, value)\n",
    "            self._node[key] = node\n",
    "            self._freq[1].append(node)\n",
    "            self._minfreq = 1\n",
    "            self._size += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Closest Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "def kClosest(self, points: List[List[int]], K: int) -> List[List[int]]:\n",
    "    return sorted(points, key=lambda x: x[0]**2 + x[1]**2)[:K]\n",
    "\n",
    "def kClosest(self, points: List[List[int]], K: int) -> List[List[int]]:\n",
    "    #pop out max\n",
    "    heap = []\n",
    "    for x, y in points:\n",
    "\n",
    "        heapq.heappush(heap, (-(x*x + y*y), x, y))\n",
    "\n",
    "        if len(heap) > K:\n",
    "            heapq.heappop(heap)\n",
    "\n",
    "    ans = [(x, y) for _, x, y in sorted(heap)]\n",
    "\n",
    "    return ans        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged K sorted list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeKLists(self, lists):\n",
    "    \"\"\"\n",
    "    :type lists: List[ListNode]\n",
    "    :rtype: ListNode\n",
    "    \"\"\"\n",
    "    heap = []\n",
    "    from heapq import heappush, heappop\n",
    "    for lis in lists:\n",
    "        heappush(heap, (lis.val, lis)) if lis else \"PASS\"\n",
    "    head = p = ListNode(-1)\n",
    "\n",
    "    while heap:\n",
    "        val, node = heappop(heap)\n",
    "        if node.next:\n",
    "            heappush(heap, (node.next.val, node.next))\n",
    "        p.next = node\n",
    "        p = p.next\n",
    "\n",
    "    return head.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Object Oriented Desgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Questions\n",
    "\n",
    "![](images/amazon14.jpg)\n",
    "\n",
    "几个准备的关键，要扣题，要答出他们想听的答案，然后再自由发挥一点点，说他们想听的话。\n",
    "\n",
    "\n",
    "What Is the STAR Interview Method?\n",
    "\n",
    ">Situation: Set the scene and give the necessary details of your example.\n",
    "\n",
    ">Task: Describe what your responsibility was in that situation.\n",
    "\n",
    ">Action: Explain exactly what steps you took to address it.\n",
    "\n",
    ">Result: Share what outcomes your actions achieved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "这个问题是容易被忽视的，但是我认为是最重要的，而且是会被99.99%被问到，这个问题是展现自己的机会，一定要抓住。\n",
    "\n",
    "I’ve been working on a lead software developer for Nomura Global Market Risk Platform for the past 3.5 years. My main responsibility is to design and develop full valuation service for our customers, regulators and risk managers. The key focus of my job is to deliver the right quality Vaule at Risk numbers in a timely sunset order for global regions at a reasonable calculation cost.\n",
    "    \n",
    "> timely deliver results\n",
    "\n",
    "> simplify and scalability\n",
    "\n",
    "> save cost, reduce time\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is your strength and weakness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Pro-active: I am very active personality, I always believe, just be a little bit more active, things will become different, when I joined a team, I will actively seek for senior guys out for a coffee and ask some very helpful advice, and further I may treat him a lunch actively and let him talk some thing about his project and advice for me. Moreover, I will try to actively find some one in person if I confront/argue with him/her to intensively during a meeting or in public, because I found it will be much more reasonable when 2 people talk exclusively with no one else there and I can often earn the trust from him back and we can become good teammates.\n",
    "\n",
    "> Deep-work: I enjoy work deeply and focusly in a flow state that I commit the entire of myself to creating valuable and meaningful things. And I truly believe this is a extremly necessary skill to be rewarded in our current economoy. Number 1, think about in this way, someone coming up in the field of marketing 10 years earlier had no idea that today they need to master digital analytics, quick learning is a must while it requied deep work. Number 2, If I can create something useful, its reachable audience (our valuable customers) is essentially limitless—which greatly magnifies my reward. On the other hand, if what I am producing is mediocre, then I am in trouble, as it’s too easy for my audience to find a better alternative online. That's the trick, to develop and deliver the best, I need deep work. \n",
    "\n",
    "> life-long learner, I have a saying from Charlie Munger, come to bed smarter than weak up, keep learning new things is a great fun. Like a philosoper from Germany said, there are two major pain for human beings, number 1\n",
    "\n",
    "\n",
    "> Weakness, talk too fast with too many information, this will be harmful to communicate with others, \n",
    "\n",
    "        1. talk as little as possible given that I've gived enough information\n",
    "        2. Listend carefully and make others finish at least 2 min talk\n",
    "        3. Use question rather than statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do you handle teammate you don't like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be active: actively look for change, doing things actlively, earn trust from him, have a coffee, lunch, a common way back home, just have a discuss. \n",
    "\n",
    "Be professional: do what I am supposed to do in a professional way, deliver produts\n",
    "\n",
    "Be \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disagree with your manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domething without asking for permission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No clear plan project\n",
    "\n",
    "讲一个project，是description不明确，具体过程需要自己figure out的\n",
    "上面project的follow up：你做这个project做了多久？是individual的project吗？\n",
    "继续follow up: 如果再给你同样长的时间你会如何优化这个system？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement Unreasonable\n",
    "\n",
    "说一个你觉得 requirement unreasonable或者实现不了的project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Tell me a time when you disagree with your manager/teammate  \n",
    "Let me share with you a quick story. ..........介绍背景，说出分歧。然后说自己怎么做，可以是讨论trade off, 可以是坚持高标准..等 结局一定说最后的选择是对的。 It proved to work well.\n",
    "\n",
    "3. Tell me a time when you received a negative feedback.\n",
    "先介绍背景,别人对你哪里不满意了，简单说以下就行，不要说很多别人如何对你不满，也不要sug·ar·coat 说自己其实没错。重点放在自己怎么解决这个问题，以及学到了什么。结果一定是好结果\n",
    "\n",
    "4. Tell me a time when you came up with a simple solution to solve a problem\n",
    "这个问题一定要让面试官信服你说的例子。先说一般的方法很耗时，自己找到一个方法很快就完成并且Deliver 了，而且很稳定，没出过问题，结果要是好的。\n",
    "\n",
    "5. Tell me your most challenging project/ a time you solved a complex problem\n",
    "扣题，怎么复杂，是deadline 紧，还是技术复杂，你怎么做的，学习了新技术，use my priavte time to work on it 等等 最后说结果或者说通过这个process 你学到了什么-baidu 1point3acres\n",
    "\n",
    "6. Tell me a time when you missed deadline \n",
    "先介绍背景 解释为何会miss 你是怎么把损失降到最低的，最后结果是好的，影响不是很大\n",
    "\n",
    "7. Biggest mistake or failure \n",
    "8. Tell me a time when you took on something significant outside your area of responsibility\n",
    "9. Tell me a time when you take caculated rist \n",
    "10 Tell me a time when you did something without asking approval from you manager\n",
    "11 Tell me a time when you dive deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接上一个帖子，把前段时间准备亚麻面试的资料贴出来，方便大家准备。我也是在地里看了很多大神贴的BQ，真的特别有用，撇开面试不谈，就单纯从更好的了解自己的方面，也是很不错的。起码以后在准备其他家面试的时候，谈到自己的经历可以有话讲了。   Amazon interview preparation.docx (34.93 KB, 下载次数: 1419) \n",
    "\n",
    "\n",
    "十四条圣经没有条条都准备case，因为经历实在太少削尖了脑袋也想不出了。。。但是感觉最重要的还是要把这些case连成一个你自己的故事，有连贯性，做到心中有数，这样在被问到没有准备的问题的时候，可以稍加润色就回答出来。\n",
    "-baidu 1point3acres\n",
    "Some general questions:\n",
    "\n",
    "Why Amazon?\n",
    "Because I know Amazon is a top internet retailing company with a strong focus on customer experience. And there are a lot of talented people in amazon creating amazing products to make people’s life easier. They are always showing strong ownership to their projects and they always want to make things perfect. Those spirits do touch my heart. I remember when I just started to lead smart log analyzer project, everything is new to me. And I’m so passionate about creating great services for customers to save their precious time and money. They could have people hired to sit there watching the visuals we provide, and trying to do treat hunting, to see if there are malicious events among them. But we want it to be more convenient. We want our system to take care of all the stuff automatically. It will detect the malicious stuff, evaluate them, report them and provide suggestions and solve them automatically. The customer only needs to do clicks on the website to make simple decisions based on the suggestions system provide and they can focus more on their own things. That is really similar with Quilt. Quilt also does a great job to help customers focus on their codes. It will take care of patching automatically for hosts. That’s really amazing for customer. So, we have similar spirits. That’s one big reason why I want to join Amazon. \n",
    "Secondly, the growth of amazon is so impressive, it is not only an online retail shop, it also has a wide range of products like Alexa, kindle, fire tablet and TV, Amazon web service, etc. There are so many fantastic technologies and products here. I will never feel boring if I am in amazon. And I’ll be excited about all the amazing things around me everyday. I can learn a lot of new technologies here. Beside that, I can also learn to work with solutions with full-stack point of view, by engaging requirements, front-end, back-end, storage and all the other stuff. I can understand the problems and solutions thoroughly.\n",
    "\n",
    "\n",
    "Why you choose this position?\n",
    "The job I applied is Software development engineer in Amazon web service quilt team. The reason why I choose this job is I have the similar experience. I remember when I just started to lead smart log analyzer project, everything is new to me. And I’m so passionate about creating great services for customers to save their precious time and money. They could have people hired to sit there watching the visuals we provide, and trying to do treat hunting, to see if there are malicious events among them. But we want it to be more convenient. We want our system to take care of all the stuff automatically. It will detect the malicious stuff, evaluate them, report them and provide suggestions and solve them automatically. The customer only needs to do clicks on the website to make simple decisions based on the suggestions system provide and they can focus more on their own things. That is really similar with Quilt. Quilt also does a great job to help customers focus on their codes. It will take care of patching automatically for hosts. That’s really amazing for customer. So, we have similar spirits. That’s one big reason why I want to join Amazon. \n",
    "Another big reason is amazon. the growth of amazon is so impressive, it is not only an online retail shop, it also has a wide range of products like Alexa, kindle, fire tablet and TV, Amazon web service, etc. There are so many fantastic technologies and products here. I will never feel boring if I am in amazon. And I’ll be excited about all the amazing things around me everyday. I can learn a lot of new technologies here. Beside that, I can also learn to work with solutions with full-stack point of view, by engaging requirements, front-end, back-end, storage and all the other stuff. I can understand the problems and solutions thoroughly.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The biggest mistake you made and what did you learn from it? (earn trust, customer obsession)\n",
    "Case 1: The biggest mistake I’ve made happened when I led the smartloganalyzer project for the first time. The original schedule is week, but I suddenly received a message from my manager says that he will show a smartloganalyzer demo to one customer after two days. And at that time I was working on building the alerting system, that will be an important part of the demo. But I paid too much attention on details, I want to make everything perfect. I didn’t notice that I don’t have enough time to finish all the details. Last day before the demo day, my manager pointed that out. I apologized to him and then we started to figure out if there is a way to keep the demo the same as what we want it to be, but sacrificing some backend performance that customer won’t notice, cause it is just a demo. After the demo, I can rewrite the code to meet my requirements. Fortunately, the demonstration was not affected in the end. But from this mistake, I learnt that details are definitely important, but I also need to pay attention to the whole schedule, I need to always keep good communication with my teammates when I have my plan. I need to make sure that my schedule won’t affect other’s schedule.\n",
    "\n",
    "Case 2: I remember that after we first delivered the 5.1 version of SLA to customer, which is the version that first with machine learning feature and alerting feature. But the customer reported that they can not see the alerts. It is very weird cause after all the checks, all the features are running smoothly in the dev machine, but when it comes to the sensor, the alerting part will fail. After tracking the logs and error message, I found that the alerting system was not able to start at the very beginning. It seems that it doesn’t have the proper environment to run. Then I noticed that all the python related stuff in the system are based on python 3, except elastalert, which is based on python 2. So I double checked the document, I didn’t document the detail in the documentation. So the sensor doesn’t have python 2 environment. It is definitely a silly mistake. I apologized to my manager and the customer. And we added the python 2 envrionment to a new sensor as soon as possible and sent it to customer again. So, after that, I learnt that I should pay attention to each small detail during the development process, and document them in time so that we won’t forget. I need to make sure that all the things I delivered are fully qualified.\n",
    "-baidu 1point3acres\n",
    "\n",
    "Most challenging project-baidu 1point3acres\n",
    "The most challenging project is my current smartloganaylzer project. It is challenging because I need to implement all the new features on my own. It requires me to build machine learning tools for network threat hunting, I haven’t done anything related to threat hunting before. And It also requires me to build RESTful APIs for the tools. I haven’t developed any RESTful API before either. It also requires me to build alerting system and But the time is not unlimited, so I started to devote more time on the project, even my private time. I googled a lot of papers related to threat hunting, like malicious url, dnstuneling, network behavior. When I came up with some ideas, I would discuss with my manager to make sure the plan is feasible. And then I learnt Go as quick as possible so that I can design and implement all the RESTful APIs on time. Finally, all the new features have been implemented on time and we received positive feedbacks from the customer. So through this process, I learnt that it is so important to be curious and keep learning, the more you read and learn, the more problems you can solve. The feeling of ownership is really really important, the product is just like your own child. So “I don’t know how to do it” will never be the excuse.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Couldn’t finish tasks before deadline\n",
    "I remember last time I was building the alerting system, my original schedule is one week, but my manager suddenly sent me an email said that he needs to show a demo to a customer two days later. One core feature of the demo is the alerting system. So I was asked to realize the function before two days deadline. If I still follow the original schedule, I definitely can not finish that. My original schedule is to let the alerting system generate rules automatically based on dynamic data. But I can not finish that in such a short time. So I figured out another temporary solution with my manager, is to make it a fake automation temporarily, to preset all the parameters and processes. If you run it, it will behave like generating rules automatically, so for the demo, the customer will have exactly the same experience. And I can also finish that before deadline. After that, I can make it real automation.\n",
    "If I couldn’t finish tasks before deadline, I will discuss with my colleagues, trying to figure out a way that can improve the efficiency and If necessary, I will use my private time to keep working on the task. After all, finishing the task with high quality as soon as possible is what we want. I’ll never sacrifice the customer experience or the quality of the product because of that. Customer experience is always the most important. We must make sure that the product we are gonna deliver is qualified. We can sacrifice our own time to try to finish the tasks. If we still can not finish the tasks, we will communicate with customers and related people, to tell them why and earn their trust. At the same time, we will try our best to finish the tasks as soon as possible.\n",
    "\n",
    "1. Customer Obsession\n",
    "Leaders start with the customer and work backward. They work vigorously to earn and keep customer trust. Although leaders pay attention to competitors, they obsess over customers.\n",
    "\n",
    "Case 1: When I led the smartloganalyzer project at the first time, it is very challenging to me. Cause I have no idea how to build the threat hunting structure. In order to understand it better, I googled a lot of papers and learnt a lot of basic concepts about network threat hunting. Based on that, I started to work with customers to figure out what kind of problems that customers concerned the most. Cause most customers who are using our products are not professional network developer. We need to use their language to tell them the story. They just need to know if they are under specific threats, they don’t care about how we find the threats. All they need to do is just make easy  decisions based on the suggestions we provide. The system will take care of all the other stuff. Like if there are brute force password attacking, the system will bubble up an alert and send an email to customer to let them know, and also providing them the links to the detailed dashboards. They can choose the suggestions provided by system, like putting the ip into the banlist.. check 1point3acres for more.\n",
    "So, finally, after the delivery, we get positive feedbacks from customers. We are always trying our best to listen to our customers and provide the best experience for them.\n",
    "\n",
    "• Who was your most difficult customer?\n",
    "• Give me an example of a time when you did not meet a client’s expectation. What happened, and how did you attempt to rectify the situation?\n",
    "• When you’re working with a large number of customers, it’s tricky to deliver excellent service to them all. How do you go about prioritizing your customers’ needs?\n",
    "• Tell the story of the last time you had to apologize to someone.\n",
    "\n",
    "2. Ownership\n",
    "Leaders are owners. They think long term and don’t sacrifice long-term value for short-term results. They act on behalf of the entire company, beyond just their own team. They never say “that’s not my job.\n",
    "\n",
    "Case 1: When I worked on the SLA project, I was required to deploy elastalert and create few rules for the alerting system. Our alerting system is based on various elasticsearch indexes, and the situations and requirements for each index are definitely different. Since I was the person who was leading SLA project, I want my customers to always have the best experience. So I started to think about automate the generation. After the agreement from my manager, I categorized the current rules and the future rules based on different scenarios and requirements. Then I wrote a bunch of shell scripts to do the automation. I also created the APIs for those alerts, so if the customer doesn’t want the rule to be enabled, he can just click on website to turn it off. After delivery, we had strong positive feedbacks from customer.\n",
    "\n",
    "• Tell me about a time when you had to leave a task unfinished.\n",
    "• Tell me about a time when you had to work on a project with unclear responsibilities.\n",
    "\n",
    "\n",
    "3. Invent and Simplify\n",
    "Leaders expect and require innovation and invention from their teams and always find ways to simplify. They are externally aware, look for new ideas from everywhere, and are not limited by “not invented here”. As we do new things, we accept that we may be misunderstood for long periods of time.\n",
    "\n",
    "Case 1: When I worked at CCG, we have a ticketing system to record the development process, keep tracking all the tasks, bugs. But you know the ticketing system is a little bit crowded. It only shows a long list of tickets. With the first glance, you can hardly know current process of development. So to simplify it, I used a vis timeline to show all the tickets. Then we can see the whole process clearly through the timeline. With the timeline, we can schedule the tasks more easily. Everyone is happy with that.\n",
    "\n",
    "• Tell me about a time when you gave a simple solution to a complex problem.\n",
    "• Tell me about a time when you invented something.\n",
    "\n",
    "\n",
    "4. Are Right, A Lot\n",
    "Leaders are right a lot. They have strong judgment and good instincts. They seek diverse perspectives and work to disconfirm their beliefs.\n",
    "\n",
    "Case 1: When I was building the alerting system through elastalert, I was asked to create rules for monitoring all the processes in the system. I have my initial plan to track the unique value of process names based on different sensors. But I don’t quite understand the behavior of system index, so I discussed with my manage, and he disagreed with plan. Actually we want to see the alert when the system is down, or nearly down. What we really care about is the count of processes. We want to alert when there is a significant drop in process numbers. So, after that I changed my design and everyone is happy.\n",
    "\n",
    "• Tell me about a time when you were wrong.\n",
    "• Tell me about a time when you had to work with incomplete data or information.\n",
    "\n",
    "\n",
    "5. Learn and Be Curious\n",
    "Leaders are never done learning and always seek to improve themselves. They are curious about new possibilities and act to explore them.\n",
    "\n",
    "Case 1: \n",
    "\n",
    "• Tell me about a time when you influenced a change by only asking questions.\n",
    "• Tell me about a time when you solved a problem through just superior knowledge or observation.\n",
    "My manager asked me if there’s a way to export and import kibana dashboards, visuals more easily. Cause through the GUI side, it has the number limit and it is hard to manipulate from back end. So I came up with an idea we can utilize the REST apis kibana and elasticsearch provide. We can write scripts to automate the loading process according to our own needs. I know that’s feasible. So finally I wrote the scripts and all the stuff in kibana can be exported and imported automatically in back end.\n",
    "\n",
    "6. Hire and Develop The Best\n",
    "Leaders raise the performance bar with every hire and promotion. They recognize exceptional talent and will move them throughout the organization. Leaders develop leaders and take seriously their role in coaching others.  We work on behalf of our people to invent mechanisms for development like Career Choice.\n",
    "\n",
    "Case 1: Few months ago, there was an intern assigned to my project. He was helping me build the alerting system. But I found that he gets lost about what we are doing and what he is going to do. So, I told him that it is not as complex as what he is thinking about. I explained the alerting concepts to him one by one and categorized the things what we are doing and what we are going to do. After he is getting comfortable of the whole environment and what I need him to do, I started to assign him the specific task. And he is doing pretty well. So when someone comes to a new environment, getting lost is quite normal. We need to have patience to make him get comfortable of the while environment. Otherwise the efficiency will be very low. And that will also help him get used to the working environment quickly and increase his enthusiasm and devote more to the work.\n",
    "\n",
    "• Tell me about a time when you mentored someone.\n",
    "\n",
    "7. Insist on the Highest Standards\n",
    "Leaders have relentlessly high standards – many people may think these standards are unreasonably high. Leaders are continually raising the bar and driving their teams to deliver high-quality products, services, and processes. Leaders ensure that defects do not get sent down the line and that problems are fixed so they stay fixed.\n",
    "\n",
    "Case 1: When I was building the alerting system, one of the important features is to generate alerting rules automatically. But I found that if the indexes are in a large scale, or we meet some edge cases,  the efficiency of the process will be very low. Cause we are generating a lot of duplicate rules. So I built the cache to story the previous status, if there are new alerts happening or new indexes, then the system will create corresponding new rules for them. Otherwise it will only update them or do nothing. Also if there are old rules that we do not need anymore, we will remove them. And I also created links for those rules, so that we can save some disk space. It turned out that the efficiency was improved a lot.\n",
    "\n",
    "• Tell me about a time when you couldn’t meet your own expectations on a project.\n",
    "• Tell me about a time when a team member didn’t meet your expectations on a project.\n",
    "\n",
    "\n",
    "8. Think Big\n",
    "Thinking small is a self-fulfilling prophecy. Leaders create and communicate a bold direction that inspires results. They think differently and look around corners for ways to serve customers.\n",
    "\n",
    "\n",
    "• Tell me about your proudest professional achievement.\n",
    "My proudest professional achievement is the SLA project I owned. I tried my best to make it look perfect and make my customers have best experience. I build the machine learning tools for network threat hunting, each network anomaly and malicious event will be reported to the system. And I also created the alerting system, so that we don’t need people to sit there monitoring the boring data and create rules by hands. The alerting system will do all the stuff automatically. Customers love that, cause it really saves them a lot of time and money.\n",
    "• Tell me about a time when you went way beyond the scope of the project and delivered.\n",
    "When the first version of SLA that with machine learning feature was delivered, I was starting to think about moving the machine learning platform to tensorflow. Cause one of our core features is to analyze the behavior of network. But each network has its own environment and their behaviors are definitely different, so we need to build specific judging rules and awarding rules to let it train itself. So that it can always have good performance regarding to each environment. And I’m still working on that. \n",
    "\n",
    "\n",
    "9. Bias for Action\n",
    "Speed matters in business. Many decisions and actions are reversible and do not need extensive study. We value calculated risk taking.  \n",
    "\n",
    "• Describe a time when you saw some problem and took the initiative to correct it rather than waiting for someone else to do it.\n",
    "\n",
    "• Tell me about a time when you took a calculated risk.\n",
    "\n",
    "• Tell me about a time you needed to get information from someone who wasn’t very responsive. What did you do?\n",
    "\n",
    "\n",
    "\n",
    "10. Frugality\n",
    "Accomplish more with less. Constraints breed resourcefulness, self-sufficiency, and invention.  There are no extra points for growing headcount, budget size or fixed expense.\n",
    "\n",
    "• Tell me about a time when you had to work with limited time or resources.\n",
    "\n",
    "\n",
    "11. Earn Trust\n",
    "Leaders listen attentively, speak candidly, and treat others respectfully. They are vocally self-critical, even when doing so is awkward or embarrassing.  Leaders do not believe their or their team’s body odor smells of perfume.  They benchmark themselves and their teams against the best.\n",
    "\n",
    "• What would you do if you found out that your closest friend at work was stealing?\n",
    "\n",
    "• Tell me about a time when you had to tell someone a harsh truth.\n",
    "\n",
    "\n",
    "12. Dive Deep\n",
    "Leaders operate at all levels, stay connected to the details, audit frequently, and are skeptical when metrics and anecdote differ. No task is beneath them.\n",
    "\n",
    "• Give me two examples of when you did more than what was required in any job experience.\n",
    "Create elastalert rules, not only the rules, but also automate them.\n",
    "Create a vis timeline to visual the tickets.\n",
    "\n",
    "\n",
    "13. Have Backbone; Disagree and Commit\n",
    "Leaders are obligated to respectfully challenge decisions when they disagree, even when doing so is uncomfortable or exhausting. Leaders have conviction and are tenacious. They do not compromise for the sake of social cohesion. Once a decision is determined, they commit wholly.\n",
    "\n",
    "• Tell me about a time when you did not accept the status quo.\n",
    "• Tell me about an unpopular decision of yours.\n",
    "• Tell me about a time when you had to step up and disagree with a team members approach.\n",
    "• If your direct manager was instructing you to do something you disagreed with, how would you handle it?-baidu 1point3acres\n",
    "\n",
    "\n",
    "\n",
    "14. Deliver Results\n",
    "Leaders focus on the key inputs for their business and deliver them with the right quality and in a timely fashion. Despite setbacks, they rise to the occasion and never settle.\n",
    "\n",
    "• By providing an example, tell me when you have had to handle a variety of assignments. Describe the results.\n",
    "• What is the most difficult situation you have ever faced in your life? How did you handle it?\n",
    "• Give me an example of a time when you were 75% of the way through a project, and you had to pivot strategy–how were you able to make that into a success story?. check 1point3acres for more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Obsession "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used to deliver products with a very strict time limit, we need a full run, but we don't have enough time to build the automatical trigger and monitor system, so we manually sit next the desktop and wait its back on globally. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invent and Simplify "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are Right, A lot \n",
    "正确决策，领导者在大多数情况下都能做出正确的决定，他们拥有卓越的业务判断能力和敏锐的直觉。他们寻求多样的视角，并挑战自己的观念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn and Be Curious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hire and Develop the Best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insist on the Highest Standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think Big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias for Action "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frugality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earn Trust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dive Deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliver Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "172.313px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
